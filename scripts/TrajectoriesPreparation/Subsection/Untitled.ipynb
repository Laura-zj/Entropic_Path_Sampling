{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-13T02:47:43.349572Z",
     "start_time": "2021-07-13T02:47:43.321622Z"
    }
   },
   "outputs": [],
   "source": [
    "rand_path = 'K:/project/Quantify_entropic_intermediate/Introduction_workflow/Trajectories preparation/Subsection/TDD_r2p_1_Subsection/'\n",
    "dele_path = 'K:/project/Quantify_entropic_intermediate/Introduction_workflow/Trajectories preparation/Truncation/TDD_r2p_1_dele/'\n",
    "file_list = os.listdir(dele_path)\n",
    "dele_file= rand_path + 'r_p_total_dele_P1.xyz'\n",
    "dele_list = []\n",
    "for file in file_list:\n",
    "    traj_dele = dele_path + file\n",
    "    with open(traj_dele,'r') as fr:\n",
    "        lines_list = fr.readlines()\n",
    "        file_len = len(lines_list)\n",
    "        atom_num = 22\n",
    "        for i in range(int(file_len/(atom_num+2))):            \n",
    "            dele_list.append(lines_list[i*(atom_num+2):i*(atom_num+2)+atom_num+2])\n",
    "with open(dele_file ,'w+') as fw:\n",
    "    for j in range(len(dele_list)):\n",
    "        fw.writelines(dele_list[j])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-13T02:55:58.558207Z",
     "start_time": "2021-07-13T02:55:58.503340Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "atom1_num = 4\n",
    "atom2_num = 14\n",
    "lines_list = []\n",
    "every_point_list = []\n",
    "orign_path ='K:/project/Quantify_entropic_intermediate/Introduction_workflow/Trajectories preparation/Subsection/TDD_r2p_1_Subsection/'\n",
    "dele_path = 'K:/project/Quantify_entropic_intermediate/Introduction_workflow/Trajectories preparation/Subsection/TDD_r2p_1_Subsection/'\n",
    "#orign_path = 'C:/Users/Yuan/Desktop/test/yeah/dele'\n",
    "#dele_path = 'C:/Users/Yuan/Desktop/test/yeah/P2_10-12_dele_total'\n",
    "file_list = os.listdir(orign_path)\n",
    "traj_file = orign_path + 'r_p_total_dele_P1.xyz'\n",
    "traj_dele = dele_path  + \"2.84_2.73_bondlength.xyz\"\n",
    "    #print(traj_file)\n",
    "with open(traj_file,'r') as fr:\n",
    "    for line in fr:\n",
    "        lines_list.append(line)\n",
    "    file_len = len(lines_list)\n",
    "    atom_num = eval(lines_list[0].strip())\n",
    "    #print(atom_num)\n",
    "    for i in range(int(file_len/(atom_num+2))):  \n",
    "        #print(i)\n",
    "        \n",
    "        #bond(6,13)\n",
    "        coord1_list = lines_list[i*(atom_num+2)+atom1_num+1].strip().split()\n",
    "        coord1 = [eval(coord1_list[1]),eval(coord1_list[2]),eval(coord1_list[3])]\n",
    "        coord2_list = lines_list[i*(atom_num+2)+atom2_num+1].strip().split()\n",
    "        coord2 = [eval(coord2_list[1]),eval(coord2_list[2]),eval(coord2_list[3])]\n",
    "        length1 = math.sqrt((coord1[0]-coord2[0])**2 + (coord1[1]-coord2[1])**2 + (coord1[2]-coord2[2])**2)\n",
    "        #print(length1)\n",
    "        #P1 or P2\n",
    "        #coord3_list = lines_list[i*(atom_num+2)+atom3_num+1].strip().split()\n",
    "        #coord3 = [eval(coord3_list[1]),eval(coord3_list[2]),eval(coord3_list[3])]\n",
    "        #coord4_list = lines_list[i*(atom_num+2)+atom4_num+1].strip().split()\n",
    "        #coord4 = [eval(coord4_list[1]),eval(coord4_list[2]),eval(coord4_list[3])]\n",
    "        #length2 = math.sqrt((coord3[0]-coord4[0])**2 + (coord3[1]-coord4[1])**2 + (coord3[2]-coord4[2])**2)\n",
    "        if length1 >= 2.73 and length1 < 2.84 :\n",
    "            every_point_list.append(lines_list[i*(atom_num+2):i*(atom_num+2)+atom_num+2])\n",
    "\n",
    "with open(traj_dele ,'w') as fw:\n",
    "    for j in range(len( every_point_list)):\n",
    "        fw.writelines(every_point_list[j])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-13T02:58:56.423183Z",
     "start_time": "2021-07-13T02:58:56.414205Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "#统计一共有多少个点(看文件夹下的分文件--分文件汇总)\n",
    "orign_path ='K:/project/Quantify_entropic_intermediate/Introduction_workflow/Trajectories preparation/Subsection/TDD_r2p_1_Subsection/'\n",
    "#orign_path = 'C:/Users/Yuan/Desktop/test/yeah/dele'\n",
    "#dele_path = 'C:/Users/Yuan/Desktop/test/yeah/P2_10-12_dele_total'\n",
    "file_list = os.listdir(orign_path)\n",
    "flag = 0\n",
    "traj_file= orign_path + '2.90_2.84_bondlength.xyz'\n",
    "with open(traj_file,'r') as fr:\n",
    "    lines_list = fr.readlines()\n",
    "    file_len = len(lines_list)\n",
    "    atom_num = eval(lines_list[0].strip())\n",
    "    every_point_list = []\n",
    "    for i in range(int(file_len/(atom_num+2))):  \n",
    "        flag+=1\n",
    "print(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-13T06:20:54.079628Z",
     "start_time": "2021-07-13T06:20:54.045696Z"
    }
   },
   "outputs": [],
   "source": [
    "#⑤xyz2xtc\n",
    "from __future__ import print_function\n",
    "import mdtraj as md\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "from matplotlib.colors import colorConverter\n",
    "from sklearn.decomposition import PCA\n",
    "from itertools import combinations\n",
    "from msmbuilder.cluster import MiniBatchKMedoids\n",
    "import numpy as np\n",
    "traj_path = 'K:/project/Quantify_entropic_intermediate/Introduction_workflow/Trajectories preparation/Subsection/TDD_r2p_1_Subsection/'\n",
    "top_path = 'K:/project/Quantify_entropic_intermediate/Introduction_workflow/Trajectories preparation/Subsection/TDD_r2p_1_Subsection/'\n",
    "anal_path = 'K:/project/Quantify_entropic_intermediate/Introduction_workflow/Parent analysis/'\n",
    "\n",
    "traj_origin = md.load(traj_path + '2.90_2.84_bondlength.xyz', top = top_path +'./dimerization-low-hp-C2-opt.pdb') \n",
    "traj_origin[0:10000:1].save_xtc(anal_path + '2.90_2.84_bondlength.xtc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-13T06:28:25.517446Z",
     "start_time": "2021-07-13T06:28:25.480784Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "def Total_Entropy(filename):\n",
    "    total = []\n",
    "    with open (filename,'r') as fr:\n",
    "        line_list = fr.readlines()\n",
    "        for line in line_list:\n",
    "            words = line.split()\n",
    "            #print(words)\n",
    "            if words[0] == 'TOTAL' and words[1] == 'CONFIGURATIONAL':\n",
    "                words[4]= float(words[4])\n",
    "                file = filename.split('\\\\')\n",
    "                #total_entropy = '%s\\t%s\\t%s\\t%s : %.2f'%(file[1],words[0],words[1],words[2],words[4])\n",
    "                total_entropy = '%s\\t : %.2f'%(file[1],words[4])\n",
    "                #print(total_entropy)\n",
    "    MI_tatal_entropy = path + 'MI_tatal_entropy.txt'\n",
    "    \n",
    "path = 'K:/project/Quantify_entropic_intermediate/Introduction_workflow/Parent analysis/PARENT-master/total_ouputs/'\n",
    "\n",
    "for filename in glob(path+'\\\\*.txt'):\n",
    "    Total_Entropy(filename) \n",
    "\n",
    "D1_D2_conf_file = path + 'D1_D2_conf.txt'\n",
    "file_list = os.listdir(path)\n",
    "for file in file_list:\n",
    "    D2_MI_total = 0\n",
    "    D1_entropy_total = 0\n",
    "    conf_entropy_total = 0\n",
    "    filename = path + '\\\\'+file\n",
    "    with open (filename,'r') as fr:\n",
    "        line_list = fr.readlines()\n",
    "        for line in line_list:\n",
    "            words = line.split()\n",
    "            #print(words)\n",
    "            if words[1] == '1D' :\n",
    "                D1_entropy= float(words[5])\n",
    "                D1_entropy_total = D1_entropy + D1_entropy_total\n",
    "            if words[1] == '2D' and words[3] =='MUTUAL':\n",
    "                D2_MI= float(words[6])\n",
    "                D2_MI_total = D2_MI + D2_MI_total\n",
    "                file = filename.split('\\\\')\n",
    "            if words[1] == 'CONFIGURATIONAL':\n",
    "                conf_entropy= float(words[4])\n",
    "                conf_entropy_total = conf_entropy + conf_entropy_total\n",
    "                #total_entropy = '%s\\t%s\\t%s\\t%s : %.2f'%(file[1],words[0],words[1],words[2],words[4])\n",
    "        D1_D2_conf_total  = \"%s D1_entropy_total %.2f D2_MI_total %.2f conf_entropy_total %.2f\" %(file[1],float(D1_entropy_total),float(D2_MI_total),float(conf_entropy_total))\n",
    "    with open (D1_D2_conf_file,'a') as fw:\n",
    "        fw.writelines(D1_D2_conf_total)\n",
    "        fw.writelines('\\n') \n",
    "title = []\n",
    "D1_entropy = []\n",
    "D2_MI = []\n",
    "conf_entropy = []\n",
    "with open (D1_D2_conf_file,'r') as fr:\n",
    "    line_list = fr.readlines()\n",
    "    for line in line_list:\n",
    "        words = line.split()\n",
    "        title.append(words[0])\n",
    "        D1_entropy.append(words[2])\n",
    "        D2_MI.append(words[4])\n",
    "        conf_entropy.append(words[6])\n",
    "data = {\"total_outputs\":title,\"D1_entropy\": D1_entropy,\"D2_MI\": D2_MI,\"conf_entropy\":conf_entropy}\n",
    "f1 = pd.DataFrame(data,columns = [\"total_outputs\",\"D1_entropy\",\"D2_MI\",\"conf_entropy\"])     \n",
    "f1.to_excel(path + 'total_outputs.xls',sheet_name='data',index=None)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
